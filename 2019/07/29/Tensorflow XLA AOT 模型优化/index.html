<!DOCTYPE html>
<html>
<head>
    
<!-- Google Analytics -->
<script>
window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
ga('create', 'true', 'auto');
ga('send', 'pageview');
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>
<!-- End Google Analytics -->


    

    



    <meta charset="utf-8">
    
    <meta name="google-site-verification" content="true">
    
    
    
    <title>Tensroflow XLA AOT 模型优化 | EdwardZhang&#39;s Blog | Life starts at the end of your comfort zone. ⚽ 🏂 🏃 🚴 ⌨️</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#3F51B5">
    
    
    <meta name="keywords" content="DeepLearning">
    <meta name="description" content="最近团队在APM方向发力，需要在产品的深度学习模型的速度和占用空间大小两个维度来进行提升 目前使用的是Tensorflow Lite的格式在进行模型运算，想通过Tensorflow官方在2017年推出的预研项目XLA对模型进行优化，在官方示例过程的结论中模型使用XLA/AOT优化的模型比之前使用.pb格式的模型运行速度会提升10%~200%（有个别情况），占用空间会有4x的缩小 本文将逐一展示完">
<meta name="keywords" content="DeepLearning">
<meta property="og:type" content="article">
<meta property="og:title" content="Tensroflow XLA AOT 模型优化">
<meta property="og:url" content="https://edward7zhang.github.io/2019/07/29/Tensorflow XLA AOT 模型优化/index.html">
<meta property="og:site_name" content="EdwardZhang&#39;s Blog">
<meta property="og:description" content="最近团队在APM方向发力，需要在产品的深度学习模型的速度和占用空间大小两个维度来进行提升 目前使用的是Tensorflow Lite的格式在进行模型运算，想通过Tensorflow官方在2017年推出的预研项目XLA对模型进行优化，在官方示例过程的结论中模型使用XLA/AOT优化的模型比之前使用.pb格式的模型运行速度会提升10%~200%（有个别情况），占用空间会有4x的缩小 本文将逐一展示完">
<meta property="og:image" content="https://i.loli.net/2019/07/30/5d3fb86bbc95b76560.jpg">
<meta property="og:image" content="https://i.loli.net/2019/07/30/5d3fcf560633657230.png">
<meta property="og:image" content="https://i.loli.net/2019/07/30/5d3fd9484d72823389.png">
<meta property="og:image" content="https://i.loli.net/2019/07/30/5d3fdb4d90ce710040.png">
<meta property="og:image" content="https://i.loli.net/2019/07/30/5d3fd82750fad80574.png">
<meta property="og:image" content="https://i.loli.net/2019/07/30/5d3fd82760ed015529.png">
<meta property="og:updated_time" content="2019-07-31T06:14:25.995Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Tensroflow XLA AOT 模型优化">
<meta name="twitter:description" content="最近团队在APM方向发力，需要在产品的深度学习模型的速度和占用空间大小两个维度来进行提升 目前使用的是Tensorflow Lite的格式在进行模型运算，想通过Tensorflow官方在2017年推出的预研项目XLA对模型进行优化，在官方示例过程的结论中模型使用XLA/AOT优化的模型比之前使用.pb格式的模型运行速度会提升10%~200%（有个别情况），占用空间会有4x的缩小 本文将逐一展示完">
<meta name="twitter:image" content="https://i.loli.net/2019/07/30/5d3fb86bbc95b76560.jpg">
    
        <link rel="alternate" type="application/atom+xml" title="EdwardZhang&#39;s Blog" href="/atom.xml">
    
    <link rel="shortcut icon" href="/img/favicon.png">
    <link rel="stylesheet" href="//unpkg.com/hexo-theme-material-indigo@latest/css/style.css">
    <script>window.lazyScripts=[]</script>

    <!-- custom head -->
    

</head>

<body>
    <div id="loading" class="active"></div>

    <aside id="menu" class="hide" >
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="icon icon-lg icon-close"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(/img/brand.jpg)">
      <div class="brand">
        <a href="/" class="avatar waves-effect waves-circle waves-light">
          <img src="/img/avatar.jpg">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">EdwardZhang</h5>
          <a href="mailto:super7edwardzhang@gmail.com" title="super7edwardzhang@gmail.com" class="mail">super7edwardzhang@gmail.com</a>
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
            <li class="waves-block waves-effect">
              <a href="/"  >
                <i class="icon icon-lg icon-home"></i>
                Homepage
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/archives"  >
                <i class="icon icon-lg icon-archives"></i>
                Archives
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/tags"  >
                <i class="icon icon-lg icon-tags"></i>
                Tags
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/photo"  >
                <i class="icon icon-lg icon-photo"></i>
                Album
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://github.com/Edward7Zhang" target="_blank" >
                <i class="icon icon-lg icon-github"></i>
                Github
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://weibo.com/u/3100298257/home?wvr=5" target="_blank" >
                <i class="icon icon-lg icon-weibo"></i>
                Weibo
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://www.instagram.com/major7edward/" target="_blank" >
                <i class="icon icon-lg icon-instagram"></i>
                Instagram
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/link"  >
                <i class="icon icon-lg icon-link"></i>
                Friends&#39; Link
              </a>
            </li>
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">Tensroflow XLA AOT 模型优化</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input" autocomplete="off" placeholder="Search">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menuShare">
            <i class="icon icon-lg icon-share-alt"></i>
        </a>
        
    </div>
</header>
<header class="content-header post-header">

    <div class="container fade-scale">
        <h1 class="title">Tensroflow XLA AOT 模型优化</h1>
        <h5 class="subtitle">
            
                <time datetime="2019-07-29T12:24:12.000Z" itemprop="datePublished" class="page-time">
  2019-07-29
</time>


            
        </h5>
    </div>

    


</header>


<div class="container body-wrap">
    
    <aside class="post-widget">
        <nav class="post-toc-wrap post-toc-shrink" id="post-toc">
            <h4>TOC</h4>
            <ol class="post-toc"><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Step-1-使用XLA将模型编译为AOT（ahead-of-time）代码的步骤"><span class="post-toc-number">1.</span> <span class="post-toc-text">Step -1: 使用XLA将模型编译为AOT（ahead-of-time）代码的步骤</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#环境"><span class="post-toc-number">1.1.</span> <span class="post-toc-text">环境</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#文件目录"><span class="post-toc-number">1.2.</span> <span class="post-toc-text">文件目录</span></a></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Step-0-编译tfcomfile"><span class="post-toc-number">2.</span> <span class="post-toc-text">Step 0: 编译tfcomfile</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Step-1-固化模型"><span class="post-toc-number">3.</span> <span class="post-toc-text">Step 1:  固化模型</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Step-2-graph-config-pbtxt"><span class="post-toc-number">4.</span> <span class="post-toc-text">Step 2: graph.config.pbtxt</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Step-3-编写bazel-BUILD脚本"><span class="post-toc-number">5.</span> <span class="post-toc-text">Step 3: 编写bazel BUILD脚本</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#内部参数解释："><span class="post-toc-number">5.0.1.</span> <span class="post-toc-text">内部参数解释：</span></a></li></ol></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Step-4-编译对应平台二进制文件-o-h"><span class="post-toc-number">6.</span> <span class="post-toc-text">Step 4: 编译对应平台二进制文件 .o .h</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Step-5-编写代码调用AOT模型"><span class="post-toc-number">7.</span> <span class="post-toc-text">Step 5: 编写代码调用AOT模型</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#项目Java书写对应native方法生成对应JNI头文件："><span class="post-toc-number">7.1.</span> <span class="post-toc-text">项目Java书写对应native方法生成对应JNI头文件：</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#生成头文件com-qihoo-cleandroid-sdk-imageclassfier-core-classfier-process-CustomClassifier-h"><span class="post-toc-number">7.2.</span> <span class="post-toc-text">生成头文件com_qihoo_cleandroid_sdk_imageclassfier_core_classfier_process_CustomClassifier.h</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#编写C-代码实现模型调用com-qihoo-cleandroid-sdk-imageclassfier-core-classfier-process-CustomClassifier-cc"><span class="post-toc-number">7.3.</span> <span class="post-toc-text">编写C++代码实现模型调用com_qihoo_cleandroid_sdk_imageclassfier_core_classfier_process_CustomClassifier.cc</span></a></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Step-6-编写BUILD"><span class="post-toc-number">8.</span> <span class="post-toc-text">Step 6: 编写BUILD</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Step-7-编译对应平台最终产物-so"><span class="post-toc-number">9.</span> <span class="post-toc-text">Step 7: 编译对应平台最终产物 .so</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#实验结论"><span class="post-toc-number">10.</span> <span class="post-toc-text">实验结论</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Reference"><span class="post-toc-number">11.</span> <span class="post-toc-text">Reference</span></a></li></ol>
        </nav>
    </aside>


<article id="post-Tensorflow XLA AOT 模型优化"
  class="post-article article-type-post fade" itemprop="blogPost">

    <div class="post-card">
        <h1 class="post-card-title">Tensroflow XLA AOT 模型优化</h1>
        <div class="post-meta">
            <time class="post-time" title="2019-07-29 20:24:12" datetime="2019-07-29T12:24:12.000Z"  itemprop="datePublished">2019-07-29</time>

            


            
<span id="busuanzi_container_page_pv" title="文章总阅读量" style='display:none'>
    <i class="icon icon-eye icon-pr"></i><span id="busuanzi_value_page_pv"></span>
</span>


        </div>
        <div class="post-content" id="post-content" itemprop="postContent">
            <blockquote>
<p>最近团队在APM方向发力，需要在产品的深度学习模型的速度和占用空间大小两个维度来进行提升</p>
<p>目前使用的是Tensorflow Lite的格式在进行模型运算，想通过Tensorflow官方在2017年推出的预研项目XLA对模型进行优化，在官方示例过程的结论中模型使用XLA/AOT优化的模型比之前使用.pb格式的模型运行速度会提升10%~200%（有个别情况），占用空间会有4x的缩小</p>
<p>本文将逐一展示完整优化过程及遇到的坑（解决方案）。</p>
</blockquote>
<h1 id="Step-1-使用XLA将模型编译为AOT（ahead-of-time）代码的步骤"><a href="#Step-1-使用XLA将模型编译为AOT（ahead-of-time）代码的步骤" class="headerlink" title="Step -1: 使用XLA将模型编译为AOT（ahead-of-time）代码的步骤"></a>Step -1: 使用XLA将模型编译为AOT（ahead-of-time）代码的步骤</h1><ol>
<li><p>编译tfcomfile</p>
</li>
<li><p>固化模型</p>
</li>
<li><p>graph.config.pbtxt</p>
</li>
<li><p>编写bazel BUILD脚本</p>
</li>
<li><p>编译对应平台二进制文件 .o .h</p>
</li>
<li><p>编写代码调用AOT模型</p>
</li>
<li><p>编写BUILD</p>
</li>
<li><p>编译对应平台最终产物 .so</p>
<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><ul>
<li>Ubuntu18.04</li>
<li>Bazel 0.24</li>
<li>jdk 8</li>
<li>NDK</li>
<li>SDK</li>
</ul>
<h2 id="文件目录"><a href="#文件目录" class="headerlink" title="文件目录"></a>文件目录</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div></pre></td><td class="code"><pre><div class="line">//tensorflow/compiler/aot/</div><div class="line">│  aot_only_var_handle_op.cc</div><div class="line">│  benchmark.cc</div><div class="line">│  benchmark.h</div><div class="line">│  benchmark_main.template</div><div class="line">│  benchmark_test.cc</div><div class="line">│  BUILD</div><div class="line">│  codegen.cc</div><div class="line">│  codegen.h</div><div class="line">│  codegen_test.cc</div><div class="line">│  codegen_test_h.golden</div><div class="line">│  codegen_test_o.golden</div><div class="line">│  compile.cc</div><div class="line">│  compile.h</div><div class="line">│  embedded_protocol_buffers.cc</div><div class="line">│  embedded_protocol_buffers.h</div><div class="line">│  flags.cc</div><div class="line">│  flags.h</div><div class="line">│  test.cc</div><div class="line">│  test_graph_tfadd.config.pbtxt</div><div class="line">│  test_graph_tfadd.pbtxt</div><div class="line">│  test_graph_tfunknownop.config.pbtxt</div><div class="line">│  test_graph_tfunknownop.pbtxt</div><div class="line">│  test_graph_tfunknownop2.config.pbtxt</div><div class="line">│  test_graph_tfunknownop3.config.pbtxt</div><div class="line">│  tfcompile.bzl</div><div class="line">│  tfcompile_main.cc</div><div class="line">│</div><div class="line">├─custom</div><div class="line">│  │  BUILD</div><div class="line">│  │  com_qihoo_cleandroid_sdk_imageclassfier_core_classfier_process_CustomClassifier.cc</div><div class="line">│  │  com_qihoo_cleandroid_sdk_imageclassfier_core_classfier_process_CustomClassifier.h</div><div class="line">│  │  custom_interface.config.pbtxt</div><div class="line">│  │  custom_interface_lib.h</div><div class="line">│  │  custom_interface_tfcompile_function.o</div><div class="line">│  │  custom_interface_tfcompile_metadata.o</div><div class="line">│  │  debug.cc</div><div class="line">│  │  debug.h</div><div class="line">│  │  figure-65.png</div><div class="line">│  │  figure-66.jpg</div><div class="line">│  │  frozen_custom_010.pb</div><div class="line">│  │  input_image.py</div><div class="line">│  │  libcustom_interface.a</div><div class="line">│  │  libcustom_interface.pic.a</div><div class="line">│  │  libcustom_interface.so</div><div class="line">│  │  lib_custom_interface.so</div><div class="line">│  │  log.h</div><div class="line">│  │  log_stream.h</div><div class="line">│  │  out.h</div><div class="line">│  │  out_helper.o</div><div class="line">│  │  out_model.o</div><div class="line">│  │  predict_model.py</div><div class="line">│  │  Screenshot_67.jpg</div><div class="line">│  │  Screenshot_68.png</div><div class="line">│  │  tfcompile_h_o.py</div><div class="line">│  │  __init__.py</div><div class="line">│  │</div><div class="line">│  ├─arm64-v8a</div><div class="line">│  │      libcustom_interface.so</div><div class="line">│  │      lib_custom_interface.so</div><div class="line">│  │</div><div class="line">│  └─armeabi-v7a</div><div class="line">│          libcustom_interface.so</div><div class="line">│          lib_custom_interface.so</div><div class="line">│</div><div class="line">└─tests</div><div class="line">        BUILD</div><div class="line">        make_test_graphs.py</div><div class="line">        test_graph_tfadd.config.pbtxt</div><div class="line">        test_graph_tfadd_with_ckpt.config.pbtxt</div><div class="line">        test_graph_tfassert_eq.config.pbtxt</div><div class="line">        test_graph_tfcond.config.pbtxt</div><div class="line">        test_graph_tffunction.config.pbtxt</div><div class="line">        test_graph_tfgather.config.pbtxt</div><div class="line">        test_graph_tfmatmul.config.pbtxt</div><div class="line">        test_graph_tfmatmulandadd.config.pbtxt</div><div class="line">        test_graph_tfsplits.config.pbtxt</div><div class="line">        test_graph_tftop_k.config.pbtxt</div><div class="line">        test_graph_tfvariable.config.pbtxt</div><div class="line">        test_graph_tfvariable_sequential_updates.config.pbtxt</div><div class="line">        tfcompile_test.cc</div></pre></td></tr></table></figure>
</li>
</ol>
<h1 id="Step-0-编译tfcomfile"><a href="#Step-0-编译tfcomfile" class="headerlink" title="Step 0: 编译tfcomfile"></a>Step 0: 编译tfcomfile</h1><ul>
<li><p>首先编译tfcomfile其实就是编译tensorflow源码中的一部分，但这一部分的编译却需要整个工程的依赖</p>
<ol>
<li><p>下载源码</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git <span class="built_in">clone</span> --recurse-submodules https://github.com/tensorflow/tensorflow</div></pre></td></tr></table></figure>
<p>其中<strong>–recurse-submodules</strong>参数是必须的，用于获取TensorFlow依赖的protobuf库.</p>
</li>
<li><p>配置TensorFlow</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> ~/tensorflow</div><div class="line">./configure</div></pre></td></tr></table></figure>
<p>需要注意配置编译项的一些规则</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line">You have bazel 0.25.0 installed.</div><div class="line">Please specify the location of python. [Default is C:\ProgramData\Anaconda3\python.exe]: </div><div class="line"></div><div class="line"></div><div class="line">Found possible Python library paths:</div><div class="line">  C:\ProgramData\Anaconda3\lib\site-packages</div><div class="line">Please input the desired Python library path to use.  Default is [C:\ProgramData\Anaconda3\lib\site-packages]</div><div class="line"></div><div class="line">Do you wish to build TensorFlow with XLA JIT support? [y/N]: Y</div><div class="line">XLA JIT support will be enabled <span class="keyword">for</span> TensorFlow.</div><div class="line"></div><div class="line">Do you wish to build TensorFlow with ROCm support? [y/N]: N</div><div class="line">No ROCm support will be enabled <span class="keyword">for</span> TensorFlow.</div><div class="line"></div><div class="line">Do you wish to build TensorFlow with CUDA support? [y/N]: N</div><div class="line">No CUDA support will be enabled <span class="keyword">for</span> TensorFlow.</div><div class="line"></div><div class="line">Please specify optimization flags to use during compilation when bazel option <span class="string">"--config=opt"</span> is specified [Default is</div><div class="line">/arch:AVX]: </div><div class="line"></div><div class="line"></div><div class="line">Would you like to override eigen strong inline <span class="keyword">for</span> some C++ compilation to reduce the compilation time? [Y/n]: N</div><div class="line">Not overriding eigen strong inline, some compilations could take more than 20 mins.</div><div class="line"></div><div class="line">Preconfigured Bazel build configs. You can use any of the below by adding <span class="string">"--config=&lt;&gt;"</span> to your build <span class="built_in">command</span>. See .ba</div><div class="line">zelrc <span class="keyword">for</span> more details.</div><div class="line">        --config=mkl            <span class="comment"># Build with MKL support.</span></div><div class="line">        --config=monolithic     <span class="comment"># Config for mostly static monolithic build.</span></div><div class="line">        --config=gdr            <span class="comment"># Build with GDR support.</span></div><div class="line">        --config=verbs          <span class="comment"># Build with libverbs support.</span></div><div class="line">        --config=ngraph         <span class="comment"># Build with Intel nGraph support.</span></div><div class="line">        --config=numa           <span class="comment"># Build with NUMA support.</span></div><div class="line">        --config=dynamic_kernels        <span class="comment"># (Experimental) Build kernels into separate shared objects.</span></div><div class="line">        --config=v2             <span class="comment"># Build TensorFlow 2.x instead of 1.x.</span></div><div class="line">Preconfigured Bazel build configs to DISABLE default on features:</div><div class="line">        --config=noaws          <span class="comment"># Disable AWS S3 filesystem support.</span></div><div class="line">        --config=nogcp          <span class="comment"># Disable GCP support.</span></div><div class="line">        --config=nohdfs         <span class="comment"># Disable HDFS support.</span></div><div class="line">        --config=noignite       <span class="comment"># Disable Apache Ignite support.</span></div><div class="line">        --config=nokafka        <span class="comment"># Disable Apache Kafka support.</span></div><div class="line">        --config=nonccl         <span class="comment"># Disable NVIDIA NCCL support.</span></div><div class="line">Configuration finished</div></pre></td></tr></table></figure>
<p>最需要注意的是其中的：<code>Do you wish to build TensorFlow with XLA JIT support? [y/N]: Y</code>!!!这是使用XLA的关键</p>
</li>
<li><p>开始编译tfcompile</p>
<p>tfcompile的Bazel脚本入口在<code>//tensorflow/compiler/aot:tfcompile</code></p>
<p>执行命令进行编译</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bazel build //tensorflow/compiler/aot:tfcompile</div></pre></td></tr></table></figure>
</li>
</ol>
<blockquote>
<p>讲一下这一步骤中遇到的坑</p>
<ul>
<li>首先编译源码的过程中不同资源是异步编译的经常会出现找不到包的问题，可以多尝试执行上一命令重复进行编译即可</li>
<li>在编译过程中会首先去请求下载各种依赖，这一过程中会出现依赖方已升级版本但本地请求需要验证SHA256（本地SHA256是在代码中写死的）不匹配这一问题，可以根据日志定位依赖下载脚本位置修改对应SHA256值即可</li>
<li>bazel编译过程在下载依赖后是有缓存机制的不必担心下载后的依赖丢失（前提是不执行<code>bazel clean</code>）</li>
<li>在编译tfcompile过程中如果遇到不论在什么网络状态在都无法编译通过的问题尝试<code>bazel clean</code>后重新执行命令或在项目根目录执行<code>bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package</code>进行依赖下载构建依赖包成功后再次执行tfcompile编译命令就会顺畅很多</li>
</ul>
</blockquote>
</li>
</ul>
<h1 id="Step-1-固化模型"><a href="#Step-1-固化模型" class="headerlink" title="Step 1:  固化模型"></a>Step 1:  固化模型</h1><p>这一步中需要将graph与checkpoints冻结形成.pb格式的固化模型这是之后形成二进制文件的原料</p>
<p>这一步很容易没有什么坑 ；)</p>
<h1 id="Step-2-graph-config-pbtxt"><a href="#Step-2-graph-config-pbtxt" class="headerlink" title="Step 2: graph.config.pbtxt"></a>Step 2: graph.config.pbtxt</h1><p>这一步中主要是为了形成graph的描述，即注明该graph的输入节点的节点名、入参tensor大小，输出节点的节点名等参数</p>
<p>有两种方式可以形成该描述</p>
<ol>
<li><p>使用源码中的工具进行自动化形成（需要编写代码）</p>
<p>使用源码中的tf2xla_pb2.py可进行一些操作形成该描述</p>
<p>这里介绍另一种直观且快速的方式</p>
</li>
<li><p>通过可视化工具确定入口出口</p>
<p><img src="https://i.loli.net/2019/07/30/5d3fb86bbc95b76560.jpg" alt="NETRON"></p>
<p>通过该工具将模型导入后可扩展内部所有节点的描述，即可以得到输入节点与输出节点的描述，进行对应节点描述文件编写</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Each feed is a positional input argument for the generated function.  The order</span></div><div class="line"><span class="comment"># of each entry matches the order of each input argument.  Here “x_hold” and “y_hold”</span></div><div class="line"><span class="comment"># refer to the names of placeholder nodes defined in the graph.</span></div><div class="line">feed &#123;</div><div class="line">  id &#123; node_name: <span class="string">"input"</span> &#125;</div><div class="line">  shape &#123;</div><div class="line">    dim &#123; size: 1 &#125;</div><div class="line">    dim &#123; size: 160 &#125;</div><div class="line">    dim &#123; size: 160 &#125;</div><div class="line">    dim &#123; size: 3 &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"><span class="comment"># Each fetch is a positional output argument for the generated function.  The order</span></div><div class="line"><span class="comment"># of each entry matches the order of each output argument.  Here “x_y_prod”</span></div><div class="line"><span class="comment"># refers to the name of a matmul node defined in the graph.</span></div><div class="line">fetch &#123;</div><div class="line">  id &#123; node_name: <span class="string">"MobilenetV2/Predictions/Reshape_1"</span> &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ol>
<p>   将该文件保存为<code>graph.config.pbtxt</code></p>
<p>   该步骤完成</p>
<p>   <strong>WARNING:</strong> 需要注意在该描述文件中添加注释时只可使用<code>#</code>作为标示，否则编译不过且定位不到问题位置</p>
<h1 id="Step-3-编写bazel-BUILD脚本"><a href="#Step-3-编写bazel-BUILD脚本" class="headerlink" title="Step 3: 编写bazel BUILD脚本"></a>Step 3: 编写bazel BUILD脚本</h1><p>在这一步骤中将进行编写编译脚本很简短的配置但有一些细节需要注意：</p>
<ul>
<li><p>建议在<code>//tensorflow/compiler/aot</code>下建立自己的floder将以上生成的产物放入其中，以下操作默认操作在<code>//tensorflow/compiler/aot/custom</code>下进行</p>
</li>
<li><p>在custom目录下创建BUILD脚本文件</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">load(<span class="string">"//tensorflow/compiler/aot:tfcompile.bzl"</span>, <span class="string">"tf_library"</span>)</div><div class="line"></div><div class="line">tf_library(</div><div class="line">    name = <span class="string">"custom_interface"</span>,</div><div class="line"></div><div class="line">    cpp_class = <span class="string">"Classifier"</span>,</div><div class="line"></div><div class="line">    graph = <span class="string">"frozen_custom_010.pb"</span>,</div><div class="line"></div><div class="line">    config = <span class="string">"graph.config.pbtxt"</span>,</div><div class="line">)</div></pre></td></tr></table></figure>
<h3 id="内部参数解释："><a href="#内部参数解释：" class="headerlink" title="内部参数解释："></a>内部参数解释：</h3><ul>
<li><p><code>name</code>：即执行编译后将生成产物的名称</p>
</li>
<li><p><code>cpp_class</code>：即生成C++头文件.h中对该类的命名，可以在该类名前添加作用域such as：<code>foo::bar::Classifier</code>等自定义操作</p>
</li>
<li><p><code>graph</code>：即之前步骤中生成的冻结图.pb产物</p>
</li>
<li><p><code>config</code>：即上一步骤中产生的图描述文件</p>
<p><em>此步骤完成</em></p>
</li>
</ul>
</li>
</ul>
<h1 id="Step-4-编译对应平台二进制文件-o-h"><a href="#Step-4-编译对应平台二进制文件-o-h" class="headerlink" title="Step 4: 编译对应平台二进制文件 .o .h"></a>Step 4: 编译对应平台二进制文件 .o .h</h1><p>使用命令：<code>bazel build --verbose_failures //tensorflow/compiler/aot/custom:custom_interface</code></p>
<p>其中<code>custom_interface</code>对应上一步骤中的<code>name</code></p>
<p>鉴于之前编译过tfcompile，此步骤只是使用了该产物中的部分资源进行编译所以不会有什么坑</p>
<p>这里介绍另一种编译此步骤产物的方式，需要在编译tfcompile步骤后产生的bazel-bin文件中找到tfcompile的run文件</p>
<p>通过命令<code>tfcompile --graph=frozen_custom_010.pb --config=graph.config.pbtxt --cpp_class=&quot;Classifier&quot;</code></p>
<p>这里贴下tfcompile的具体用法其中具有编译对应平台ABI的参数：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div></pre></td><td class="code"><pre><div class="line">tfcompile performs ahead-of-time compilation of a TensorFlow graph,</div><div class="line">resulting <span class="keyword">in</span> an object file compiled <span class="keyword">for</span> your target architecture, and a</div><div class="line">header file that gives access to the functionality <span class="keyword">in</span> the object file.</div><div class="line">A typical invocation looks like this:</div><div class="line"></div><div class="line">   $ tfcompile --graph=mygraph.pb --config=myfile.pbtxt --cpp_class=<span class="string">"mynamespace::MyComputation"</span></div><div class="line"></div><div class="line">usage: ./tfcompile</div><div class="line">Flags:</div><div class="line">        --graph=<span class="string">""</span>                              string  Input GraphDef file.  If the file ends <span class="keyword">in</span> <span class="string">'.pbtxt'</span> it is expected to be <span class="keyword">in</span> the human-readable proto text format, otherwise it is expected to be <span class="keyword">in</span> the proto binary format.</div><div class="line">        --config=<span class="string">""</span>                             string  Input file containing Config proto.  If the file ends <span class="keyword">in</span> <span class="string">'.pbtxt'</span> it is expected to be <span class="keyword">in</span> the human-readable proto text format, otherwise it is expected to be <span class="keyword">in</span> the proto binary format.</div><div class="line">        --dump_fetch_nodes=<span class="literal">false</span>                bool    If <span class="built_in">set</span>, only flags related to fetches are processed, and the resulting fetch nodes will be dumped to stdout <span class="keyword">in</span> a comma-separated list.  Typically used to format arguments <span class="keyword">for</span> other tools, e.g. freeze_graph.</div><div class="line">        --target_triple=<span class="string">"x86_64-pc-linux"</span>       string  Target platform, similar to the clang -target flag.  The general format is &lt;arch&gt;&lt;sub&gt;-&lt;vendor&gt;-&lt;sys&gt;-&lt;abi&gt;.  http://clang.llvm.org/docs/CrossCompilation.html<span class="comment">#target-triple.</span></div><div class="line">        --target_cpu=<span class="string">""</span>                         string  Target cpu, similar to the clang -mcpu flag.  http://clang.llvm.org/docs/CrossCompilation.html<span class="comment">#cpu-fpu-abi</span></div><div class="line">        --target_features=<span class="string">""</span>                    string  Target features, e.g. +avx2, +neon, etc.</div><div class="line">        --entry_point=<span class="string">"entry"</span>                   string  Name of the generated <span class="keyword">function</span>.  If multiple generated object files will be linked into the same binary, each will need a unique entry point.</div><div class="line">        --cpp_class=<span class="string">""</span>                          string  Name of the generated C++ class, wrapping the generated <span class="keyword">function</span>.  The syntax of this flag is [[&lt;optional_namespace&gt;::],...]&lt;class_name&gt;.  This mirrors the C++ syntax <span class="keyword">for</span> referring to a class, <span class="built_in">where</span> multiple namespaces may precede the class name, separated by double-colons.  The class will be generated <span class="keyword">in</span> the given namespace(s), or <span class="keyword">if</span> no namespaces are given, within the global namespace.</div><div class="line">        --out_function_object=<span class="string">"out_model.o"</span>     string  Output object file containing the generated <span class="keyword">function</span> <span class="keyword">for</span> the TensorFlow model.</div><div class="line">        --out_header=<span class="string">"out.h"</span>                    string  Output header file name.</div><div class="line">        --out_metadata_object=<span class="string">"out_helper.o"</span>    string  Output object file name containing optional metadata <span class="keyword">for</span> the generated <span class="keyword">function</span>.</div><div class="line">        --out_session_module=<span class="string">""</span>                 string  Output session module proto.</div><div class="line">        --gen_name_to_index=<span class="literal">false</span>               bool    Generate name-to-index data <span class="keyword">for</span> Lookup&#123;Arg,Result&#125;Index methods.</div><div class="line">        --gen_program_shape=<span class="literal">false</span>               bool    Generate program shape data <span class="keyword">for</span> the ProgramShape method.</div><div class="line">        --xla_generate_hlo_graph=<span class="string">""</span>             string  HLO modules matching this regex will be dumped to a .dot file throughout various stages <span class="keyword">in</span> compilation.</div><div class="line">        --xla_hlo_graph_addresses=<span class="literal">false</span>         bool    With xla_generate_hlo_graph, show addresses of HLO ops <span class="keyword">in</span> graph dump.</div><div class="line">        --xla_hlo_graph_path=<span class="string">""</span>                 string  With xla_generate_hlo_graph, dump the graphs into this path.</div><div class="line">        --xla_hlo_dump_as_graphdef=<span class="literal">false</span>        bool    Dump HLO graphs as TensorFlow GraphDefs.</div><div class="line">        --xla_hlo_graph_sharding_color=<span class="literal">false</span>    bool    Assign colors based on sharding assignments when generating the HLO graphs.</div><div class="line">        --xla_hlo_tfgraph_device_scopes=<span class="literal">false</span>   bool    When generating TensorFlow HLO graphs, <span class="keyword">if</span> the HLO instructions are assigned to a specific device, prefix the name scope with <span class="string">"devX"</span> with X being the device ordinal.</div><div class="line">        --xla_log_hlo_text=<span class="string">""</span>                   string  HLO modules matching this regex will be dumped to LOG(INFO).</div><div class="line">        --xla_generate_hlo_text_to=<span class="string">""</span>           string  Dump all HLO modules as text into the provided directory path.</div><div class="line">        --xla_enable_fast_math=<span class="literal">true</span>             bool    Enable unsafe fast-math optimizations <span class="keyword">in</span> the compiler; this may produce faster code at the expense of some accuracy.</div><div class="line">        --xla_llvm_enable_alias_scope_metadata=<span class="literal">true</span>     bool    In LLVM-based backends, <span class="built_in">enable</span> the emission of !alias.scope metadata <span class="keyword">in</span> the generated IR.</div><div class="line">        --xla_llvm_enable_noalias_metadata=<span class="literal">true</span> bool    In LLVM-based backends, <span class="built_in">enable</span> the emission of !noalias metadata <span class="keyword">in</span> the generated IR.</div><div class="line">        --xla_llvm_enable_invariant_load_metadata=<span class="literal">true</span>  bool    In LLVM-based backends, <span class="built_in">enable</span> the emission of !invariant.load metadata <span class="keyword">in</span> the generated IR.</div><div class="line">        --xla_llvm_disable_expensive_passes=<span class="literal">false</span>       bool    In LLVM-based backends, <span class="built_in">disable</span> a custom <span class="built_in">set</span> of expensive optimization passes.</div><div class="line">        --xla_backend_optimization_level=3      int32   Numerical optimization level <span class="keyword">for</span> the XLA compiler backend.</div><div class="line">        --xla_disable_hlo_passes=<span class="string">""</span>             string  Comma-separated list of hlo passes to be disabled. These names must exactly match the passes<span class="string">' names; no whitespace around commas.</span></div><div class="line">        --xla_embed_ir_in_executable=false      bool    Embed the compiler IR as a string in the executable.</div><div class="line">        --xla_dump_ir_to=""                     string  Dump the compiler IR into this directory as individual files.</div><div class="line">        --xla_eliminate_hlo_implicit_broadcast=true     bool    Eliminate implicit broadcasts when lowering user computations to HLO instructions; use explicit broadcast instead.</div><div class="line">        --xla_cpu_multi_thread_eigen=true       bool    When generating calls to Eigen in the CPU backend, use multi-threaded Eigen mode.</div><div class="line">        --xla_gpu_cuda_data_dir="./cuda_sdk_lib"        string  If non-empty, speficies a local directory containing ptxas and nvvm libdevice files; otherwise we use those from runfile directories.</div><div class="line">        --xla_gpu_ftz=false                     bool    If true, flush-to-zero semantics are enabled in the code generated for GPUs.</div><div class="line">        --xla_gpu_disable_multi_streaming=false bool    If true, multi-streaming in the GPU backend is disabled.</div><div class="line">        --xla_gpu_max_kernel_unroll_factor=4    int32   Specify the maximum kernel unroll factor for the GPU backend.</div><div class="line">        --xla_dump_optimized_hlo_proto_to=""    string  Dump Hlo after all hlo passes are executed as proto binary into this directory.</div><div class="line">        --xla_dump_unoptimized_hlo_proto_to=""  string  Dump HLO before any hlo passes are executed as proto binary into this directory.</div><div class="line">        --xla_dump_per_pass_hlo_proto_to=""     string  Dump HLO after each pass as an HloProto in binary file format into this directory.</div><div class="line">        --xla_test_all_output_layouts=false     bool    Let ClientLibraryTestBase::ComputeAndCompare* test all permutations of output layouts. For example, with a 3D shape, all permutations of the set &#123;0, 1, 2&#125; are tried.</div><div class="line">        --xla_test_all_input_layouts=false      bool    Let ClientLibraryTestBase::ComputeAndCompare* test all permutations of *input* layouts. For example, for 2 input arguments with 2D shape and 4D shape, the computation will run 2! * 4! times for every possible layouts</div><div class="line">        --xla_hlo_profile=false                 bool    Instrument the computation to collect per-HLO cycle counts</div><div class="line">        --xla_dump_computations_to=""           string  Dump computations that XLA executes into the provided directory path</div><div class="line">        --xla_dump_executions_to=""             string  Dump parameters and results of computations that XLA executes into the provided directory path</div><div class="line">        --xla_backend_extra_options=""          string  Extra options to pass to a backend; comma-separated list of 'key=val<span class="string">' strings (=val may be omitted); no whitespace around commas.</span></div><div class="line">        --xla_reduce_precision=""               string  Directions for adding reduce-precision operations. Format is 'LOCATION=E,M:OPS;NAMES<span class="string">' where LOCATION is the class of locations in which to insert the operations (e.g., '</span>OP_OUTPUTS<span class="string">'), E and M are the exponent and matissa bit counts respectively, and OPS and NAMES are comma-separated (no spaces) lists of the operation types and names to which to attach the reduce-precision operations.  The NAMES string and its preceding '</span>;<span class="string">' may be omitted.  This option may be repeated to define multiple sets of added reduce-precision operations.</span></div><div class="line">        --xla_gpu_use_cudnn_batchnorm=false     bool    Allows the GPU backend to implement batchnorm HLOs using cudnn, rather than expanding them to a soup of HLOs.</div><div class="line">        --xla_cpu_use_mkl_dnn=false             bool    Generate calls to MKL-DNN in the CPU backend.</div></pre></td></tr></table></figure>
<p>最终生成三个产物:</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.loli.net/2019/07/30/5d3fcf560633657230.png" alt="产物" title="">
                </div>
                <div class="image-caption">产物</div>
            </figure>
<ul>
<li><p><code>cat custom_interface_lib.h</code>：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div><div class="line">221</div><div class="line">222</div><div class="line">223</div><div class="line">224</div><div class="line">225</div><div class="line">226</div><div class="line">227</div><div class="line">228</div><div class="line">229</div><div class="line">230</div><div class="line">231</div><div class="line">232</div><div class="line">233</div><div class="line">234</div><div class="line">235</div><div class="line">236</div><div class="line">237</div><div class="line">238</div><div class="line">239</div><div class="line">240</div><div class="line">241</div><div class="line">242</div><div class="line">243</div><div class="line">244</div><div class="line">245</div><div class="line">246</div><div class="line">247</div><div class="line">248</div><div class="line">249</div><div class="line">250</div><div class="line">251</div><div class="line">252</div><div class="line">253</div><div class="line">254</div><div class="line">255</div><div class="line">256</div><div class="line">257</div><div class="line">258</div><div class="line">259</div><div class="line">260</div><div class="line">261</div><div class="line">262</div><div class="line">263</div><div class="line">264</div><div class="line">265</div><div class="line">266</div><div class="line">267</div><div class="line">268</div><div class="line">269</div><div class="line">270</div><div class="line">271</div><div class="line">272</div><div class="line">273</div><div class="line">274</div><div class="line">275</div><div class="line">276</div><div class="line">277</div><div class="line">278</div><div class="line">279</div><div class="line">280</div><div class="line">281</div><div class="line">282</div><div class="line">283</div><div class="line">284</div><div class="line">285</div><div class="line">286</div><div class="line">287</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Generated by tfcompile, the TensorFlow graph compiler.  DO NOT EDIT!</span></div><div class="line"><span class="comment">//</span></div><div class="line"><span class="comment">// This header was generated via ahead-of-time compilation of a TensorFlow</span></div><div class="line"><span class="comment">// graph.  An object file corresponding to this header was also generated.</span></div><div class="line"><span class="comment">// This header gives access to the functionality in that object file.</span></div><div class="line"><span class="comment">//</span></div><div class="line"><span class="comment">// clang-format off</span></div><div class="line"></div><div class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> TFCOMPILE_GENERATED___xla_tensorflow_compiler_aot_custom__custom_interface_H_  <span class="comment">// NOLINT(build/header_guard)</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> TFCOMPILE_GENERATED___xla_tensorflow_compiler_aot_custom__custom_interface_H_  <span class="comment">// NOLINT(build/header_guard)</span></span></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"tensorflow/compiler/tf2xla/xla_compiled_cpu_function.h"</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"tensorflow/core/platform/types.h"</span></span></div><div class="line"></div><div class="line"><span class="keyword">namespace</span> Eigen &#123; <span class="class"><span class="keyword">struct</span> <span class="title">ThreadPoolDevice</span>;</span> &#125;</div><div class="line"><span class="keyword">namespace</span> xla &#123; <span class="class"><span class="keyword">class</span> <span class="title">ExecutableRunOptions</span>;</span> &#125;</div><div class="line"></div><div class="line"><span class="comment">// (Implementation detail) Entry point to the function in the object file.</span></div><div class="line"><span class="keyword">extern</span> <span class="string">"C"</span> <span class="keyword">void</span> __xla_tensorflow_compiler_aot_custom__custom_interface(</div><div class="line">    <span class="keyword">void</span>* result, <span class="keyword">const</span> ::xla::ExecutableRunOptions* run_options,</div><div class="line">    <span class="keyword">const</span> <span class="keyword">void</span>** args, <span class="keyword">void</span>** temps, tensorflow::int64* profile_counters);</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">// Classifier represents a computation previously specified in a</span></div><div class="line"><span class="comment">// TensorFlow graph, now compiled into executable code. This extends the generic</span></div><div class="line"><span class="comment">// XlaCompiledCpuFunction class with statically type-safe arg and result</span></div><div class="line"><span class="comment">// methods. Usage example:</span></div><div class="line"><span class="comment">//</span></div><div class="line"><span class="comment">//   Classifier computation;</span></div><div class="line"><span class="comment">//   // ...set args using computation.argN methods</span></div><div class="line"><span class="comment">//   CHECK(computation.Run());</span></div><div class="line"><span class="comment">//   // ...inspect results using computation.resultN methods</span></div><div class="line"><span class="comment">//</span></div><div class="line"><span class="comment">// The Run method invokes the actual computation, with inputs read from arg</span></div><div class="line"><span class="comment">// buffers, and outputs written to result buffers. Each Run call may also use</span></div><div class="line"><span class="comment">// a set of temporary buffers for the computation.</span></div><div class="line"><span class="comment">//</span></div><div class="line"><span class="comment">// By default each instance of this class manages its own arg, result and temp</span></div><div class="line"><span class="comment">// buffers. The AllocMode constructor parameter may be used to modify the</span></div><div class="line"><span class="comment">// buffer allocation strategy.</span></div><div class="line"><span class="comment">//</span></div><div class="line"><span class="comment">// Under the default allocation strategy, this class is thread-compatible:</span></div><div class="line"><span class="comment">// o Calls to non-const methods require exclusive access to the object.</span></div><div class="line"><span class="comment">// o Concurrent calls to const methods are OK, if those calls are made while it</span></div><div class="line"><span class="comment">//   is guaranteed that no thread may call a non-const method.</span></div><div class="line"><span class="comment">//</span></div><div class="line"><span class="comment">// The logical function signature is:</span></div><div class="line"><span class="comment">//   (arg0: f32[1,160,160,3]) -&gt; (f32[1,30])</span></div><div class="line"><span class="comment">//</span></div><div class="line"><span class="comment">// Memory stats:</span></div><div class="line"><span class="comment">//   arg bytes total:    307200</span></div><div class="line"><span class="comment">//   arg bytes aligned:  307200</span></div><div class="line"><span class="comment">//   temp bytes total:   4143008</span></div><div class="line"><span class="comment">//   temp bytes aligned: 4143104</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Classifier</span> <span class="title">final</span> :</span> <span class="keyword">public</span> tensorflow::XlaCompiledCpuFunction &#123;</div><div class="line"> <span class="keyword">public</span>:</div><div class="line">  <span class="comment">// Number of input arguments for the compiled computation.</span></div><div class="line">  <span class="keyword">static</span> <span class="keyword">constexpr</span> <span class="keyword">size_t</span> kNumArgs = <span class="number">1</span>;</div><div class="line"></div><div class="line">  <span class="comment">// Byte size of each argument buffer. There are kNumArgs entries.</span></div><div class="line">  <span class="keyword">static</span> <span class="keyword">const</span> ::tensorflow::<span class="function">int64 <span class="title">ArgSize</span><span class="params">(::tensorflow::int32 index)</span> </span>&#123;</div><div class="line">    <span class="keyword">return</span> BufferInfos()[ArgIndexToBufferIndex()[index]].size();</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// Returns static data used to create an XlaCompiledCpuFunction.</span></div><div class="line">  <span class="keyword">static</span> <span class="keyword">const</span> tensorflow::XlaCompiledCpuFunction::<span class="function">StaticData&amp; <span class="title">StaticData</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">static</span> XlaCompiledCpuFunction::StaticData* kStaticData = []()&#123;</div><div class="line">      XlaCompiledCpuFunction::StaticData* data =</div><div class="line">        <span class="keyword">new</span> XlaCompiledCpuFunction::StaticData;</div><div class="line">      set_static_data_raw_function(data, __xla_tensorflow_compiler_aot_custom__custom_interface);</div><div class="line">      set_static_data_buffer_infos(data, BufferInfos());</div><div class="line">      set_static_data_num_buffers(data, kNumBuffers);</div><div class="line">      set_static_data_arg_index_table(data, ArgIndexToBufferIndex());</div><div class="line">      set_static_data_num_args(data, kNumArgs);</div><div class="line">      set_static_data_result_index(data, kResultIndex);</div><div class="line">      set_static_data_arg_names(data, StaticArgNames());</div><div class="line">      set_static_data_result_names(data, StaticResultNames());</div><div class="line">      set_static_data_program_shape(data, StaticProgramShape());</div><div class="line">      set_static_data_hlo_profile_printer_data(</div><div class="line">          data, StaticHloProfilePrinterData());</div><div class="line"></div><div class="line">      <span class="keyword">return</span> data;</div><div class="line">    &#125;();</div><div class="line">    <span class="keyword">return</span> *kStaticData;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  Classifier(AllocMode alloc_mode =</div><div class="line">            AllocMode::ARGS_VARIABLES_RESULTS_PROFILES_AND_TEMPS)</div><div class="line">      : XlaCompiledCpuFunction(StaticData(), alloc_mode) &#123;&#125;</div><div class="line"></div><div class="line">  Classifier(<span class="keyword">const</span> Classifier&amp;) = <span class="keyword">delete</span>;</div><div class="line">  Classifier&amp; <span class="keyword">operator</span>=(<span class="keyword">const</span> Classifier&amp;) = <span class="keyword">delete</span>;</div><div class="line"></div><div class="line">  <span class="comment">// Arg methods for managing input buffers. Buffers are in row-major order.</span></div><div class="line">  <span class="comment">// There is a set of methods for each positional argument, with the following</span></div><div class="line">  <span class="comment">// general form:</span></div><div class="line">  <span class="comment">//</span></div><div class="line">  <span class="comment">// void set_argN_data(void* data)</span></div><div class="line">  <span class="comment">//   Sets the buffer of type T for positional argument N. May be called in</span></div><div class="line">  <span class="comment">//   any AllocMode. Must be called before Run to have an affect. Must be</span></div><div class="line">  <span class="comment">//   called in AllocMode::RESULTS_PROFILES_AND_TEMPS_ONLY for each positional</span></div><div class="line">  <span class="comment">//   argument, to set the argument buffers.</span></div><div class="line">  <span class="comment">//</span></div><div class="line">  <span class="comment">// T* argN_data()</span></div><div class="line">  <span class="comment">//   Returns the buffer of type T for positional argument N.</span></div><div class="line">  <span class="comment">//</span></div><div class="line">  <span class="comment">// T&amp; argN(...dim indices...)</span></div><div class="line">  <span class="comment">//   Returns a reference to the value of type T for positional argument N,</span></div><div class="line">  <span class="comment">//   with dim indices specifying which value. No bounds checking is performed</span></div><div class="line">  <span class="comment">//   on dim indices.</span></div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">void</span> <span class="title">set_arg0_data</span><span class="params">(<span class="keyword">const</span> <span class="keyword">void</span>* data)</span> </span>&#123;</div><div class="line">    set_arg_data(<span class="number">0</span>, data);</div><div class="line">  &#125;</div><div class="line">  <span class="function"><span class="keyword">float</span>* <span class="title">arg0_data</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">return</span> <span class="keyword">static_cast</span>&lt;<span class="keyword">float</span>*&gt;(arg_data(<span class="number">0</span>));</div><div class="line">  &#125;</div><div class="line">  <span class="function"><span class="keyword">float</span>&amp; <span class="title">arg0</span><span class="params">(<span class="keyword">size_t</span> dim0, <span class="keyword">size_t</span> dim1, <span class="keyword">size_t</span> dim2, <span class="keyword">size_t</span> dim3)</span> </span>&#123;</div><div class="line">    <span class="keyword">return</span> (*<span class="keyword">static_cast</span>&lt;<span class="keyword">float</span>(*)[<span class="number">1</span>][<span class="number">160</span>][<span class="number">160</span>][<span class="number">3</span>]&gt;(</div><div class="line">        arg_data(<span class="number">0</span>)))[dim0][dim1][dim2][dim3];</div><div class="line">  &#125;</div><div class="line">  <span class="function"><span class="keyword">const</span> <span class="keyword">float</span>* <span class="title">arg0_data</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123;</div><div class="line">    <span class="keyword">return</span> <span class="keyword">static_cast</span>&lt;<span class="keyword">const</span> <span class="keyword">float</span>*&gt;(arg_data(<span class="number">0</span>));</div><div class="line">  &#125;</div><div class="line">  <span class="function"><span class="keyword">const</span> <span class="keyword">float</span>&amp; <span class="title">arg0</span><span class="params">(<span class="keyword">size_t</span> dim0, <span class="keyword">size_t</span> dim1, <span class="keyword">size_t</span> dim2, <span class="keyword">size_t</span> dim3)</span> <span class="keyword">const</span> </span>&#123;</div><div class="line">    <span class="keyword">return</span> (*<span class="keyword">static_cast</span>&lt;<span class="keyword">const</span> <span class="keyword">float</span>(*)[<span class="number">1</span>][<span class="number">160</span>][<span class="number">160</span>][<span class="number">3</span>]&gt;(</div><div class="line">        arg_data(<span class="number">0</span>)))[dim0][dim1][dim2][dim3];</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// Result methods for managing output buffers. Buffers are in row-major order.</span></div><div class="line">  <span class="comment">// Must only be called after a successful Run call. There is a set of methods</span></div><div class="line">  <span class="comment">// for each positional result, with the following general form:</span></div><div class="line">  <span class="comment">//</span></div><div class="line">  <span class="comment">// T* resultN_data()</span></div><div class="line">  <span class="comment">//   Returns the buffer of type T for positional result N.</span></div><div class="line">  <span class="comment">//</span></div><div class="line">  <span class="comment">// T&amp; resultN(...dim indices...)</span></div><div class="line">  <span class="comment">//   Returns a reference to the value of type T for positional result N,</span></div><div class="line">  <span class="comment">//   with dim indices specifying which value. No bounds checking is performed</span></div><div class="line">  <span class="comment">//   on dim indices.</span></div><div class="line">  <span class="comment">//</span></div><div class="line">  <span class="comment">// Unlike the arg methods, there is no set_resultN_data method. The result</span></div><div class="line">  <span class="comment">// buffers are managed internally, and may change after each call to Run.</span></div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">float</span>* <span class="title">result0_data</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">return</span> <span class="keyword">static_cast</span>&lt;<span class="keyword">float</span>*&gt;(result_data(<span class="number">0</span>));</div><div class="line">  &#125;</div><div class="line">  <span class="function"><span class="keyword">float</span>&amp; <span class="title">result0</span><span class="params">(<span class="keyword">size_t</span> dim0, <span class="keyword">size_t</span> dim1)</span> </span>&#123;</div><div class="line">    <span class="keyword">return</span> (*<span class="keyword">static_cast</span>&lt;<span class="keyword">float</span>(*)[<span class="number">1</span>][<span class="number">30</span>]&gt;(</div><div class="line">        result_data(<span class="number">0</span>)))[dim0][dim1];</div><div class="line">  &#125;</div><div class="line">  <span class="function"><span class="keyword">const</span> <span class="keyword">float</span>* <span class="title">result0_data</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123;</div><div class="line">    <span class="keyword">return</span> <span class="keyword">static_cast</span>&lt;<span class="keyword">const</span> <span class="keyword">float</span>*&gt;(result_data(<span class="number">0</span>));</div><div class="line">  &#125;</div><div class="line">  <span class="function"><span class="keyword">const</span> <span class="keyword">float</span>&amp; <span class="title">result0</span><span class="params">(<span class="keyword">size_t</span> dim0, <span class="keyword">size_t</span> dim1)</span> <span class="keyword">const</span> </span>&#123;</div><div class="line">    <span class="keyword">return</span> (*<span class="keyword">static_cast</span>&lt;<span class="keyword">const</span> <span class="keyword">float</span>(*)[<span class="number">1</span>][<span class="number">30</span>]&gt;(</div><div class="line">        result_data(<span class="number">0</span>)))[dim0][dim1];</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// Methods for managing variable buffers. Buffers are in row-major order.</span></div><div class="line">  <span class="comment">//</span></div><div class="line">  <span class="comment">// For read-write variables we generate the following methods:</span></div><div class="line">  <span class="comment">//</span></div><div class="line">  <span class="comment">// void set_var_X_data(T* data)</span></div><div class="line">  <span class="comment">//   Sets the buffer for variable X.  Must be called before Run if the</span></div><div class="line">  <span class="comment">//   allocation mode is RESULTS_PROFILES_AND_TEMPS_ONLY.</span></div><div class="line">  <span class="comment">//</span></div><div class="line">  <span class="comment">// T* var_X_data()</span></div><div class="line">  <span class="comment">//   Returns the buffer of type T for variable X.  If the allocation mode is</span></div><div class="line">  <span class="comment">//   RESULTS_PROFILES_AND_TEMPS_ONLY then this buffer is the same as the</span></div><div class="line">  <span class="comment">//   buffer passed to set_var_X_data.</span></div><div class="line">  <span class="comment">//</span></div><div class="line">  <span class="comment">// T&amp; var_X(...dim indices...)</span></div><div class="line">  <span class="comment">//   Returns a reference to the value of type T for variable X,</span></div><div class="line">  <span class="comment">//   with dim indices specifying which value. No bounds checking is performed</span></div><div class="line">  <span class="comment">//   on dim indices.</span></div><div class="line">  <span class="comment">//</span></div><div class="line">  <span class="comment">// For readonly variables we generate the same set of methods, except that we</span></div><div class="line">  <span class="comment">// use `const T` instead of `T`.  We use `const T` to avoid erasing the</span></div><div class="line">  <span class="comment">// constness of the buffer passed to `set_var_X_data` but the underlying</span></div><div class="line">  <span class="comment">// buffer is not const (and thus the const can be safely const-cast'ed away)</span></div><div class="line">  <span class="comment">// unless `set_var_X_data` is called with a pointer to constant storage.</span></div><div class="line"></div><div class="line"> <span class="keyword">private</span>:</div><div class="line">  <span class="comment">// Number of buffers for the compiled computation.</span></div><div class="line">  <span class="keyword">static</span> <span class="keyword">constexpr</span> <span class="keyword">size_t</span> kNumBuffers = <span class="number">50</span>;</div><div class="line"></div><div class="line">  <span class="keyword">static</span> <span class="keyword">const</span> ::xla::cpu_function_runtime::<span class="function">BufferInfo* <span class="title">BufferInfos</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">static</span> <span class="keyword">const</span> ::xla::cpu_function_runtime::BufferInfo</div><div class="line">      kBufferInfos[kNumBuffers] = &#123;</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">2293760U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">1228802U</span>LL, <span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">614400U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">602112U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">301056U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">301056U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">301056U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">301056U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">301056U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">172032U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">98304U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">98304U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">98304U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">98304U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">98304U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">73728U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">55296U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">55296U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">55296U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">55296U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">55296U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">55296U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">55296U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">36864U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">24576U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">24576U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">24576U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">24576U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">24576U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">12288U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">6912U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">6144U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">6144U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">6144U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">6144U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">6144U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">2048U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">481U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">33U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">16U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">19U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">19U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">19U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">19U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">19U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">19U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">19U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">19U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">19U</span>LL, ~<span class="number">0U</span>LL&#125;),</div><div class="line">::xla::cpu_function_runtime::BufferInfo(&#123;<span class="number">16571521U</span>LL, ~<span class="number">0U</span>LL&#125;)</div><div class="line">      &#125;;</div><div class="line">    <span class="keyword">return</span> kBufferInfos;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">static</span> <span class="keyword">const</span> ::tensorflow::<span class="function">int32* <span class="title">ArgIndexToBufferIndex</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">static</span> <span class="keyword">constexpr</span> ::tensorflow::int32 kArgIndexToBufferIndex[kNumArgs] = &#123;</div><div class="line"><span class="number">1</span></div><div class="line">    &#125;;</div><div class="line">    <span class="keyword">return</span> kArgIndexToBufferIndex;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// The 0-based index of the result tuple in the temporary buffers.</span></div><div class="line">  <span class="keyword">static</span> <span class="keyword">constexpr</span> <span class="keyword">size_t</span> kResultIndex = <span class="number">38</span>;</div><div class="line"></div><div class="line">  <span class="comment">// Array of names of each positional argument, terminated by nullptr.</span></div><div class="line">  <span class="function"><span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">char</span>** <span class="title">StaticArgNames</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">return</span> <span class="literal">nullptr</span>;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// Array of names of each positional result, terminated by nullptr.</span></div><div class="line">  <span class="function"><span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">char</span>** <span class="title">StaticResultNames</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">return</span> <span class="literal">nullptr</span>;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// Shape of the args and results.</span></div><div class="line">  <span class="keyword">static</span> <span class="keyword">const</span> ::xla::<span class="function">ProgramShapeProto* <span class="title">StaticProgramShape</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">static</span> <span class="keyword">const</span> ::xla::ProgramShapeProto* kShape = <span class="literal">nullptr</span>;</div><div class="line">    <span class="keyword">return</span> kShape;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="comment">// Metadata that can be used to pretty-print profile counters.</span></div><div class="line">  <span class="keyword">static</span> <span class="keyword">const</span> ::xla::<span class="function">HloProfilePrinterData* <span class="title">StaticHloProfilePrinterData</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">static</span> <span class="keyword">const</span> ::xla::HloProfilePrinterData* kHloProfilePrinterData =</div><div class="line">      <span class="literal">nullptr</span>;</div><div class="line">    <span class="keyword">return</span> kHloProfilePrinterData;</div><div class="line">  &#125;</div><div class="line">&#125;;</div><div class="line"></div><div class="line"></div><div class="line"><span class="meta">#<span class="meta-keyword">endif</span>  <span class="comment">// TFCOMPILE_GENERATED___xla_tensorflow_compiler_aot_custom__custom_interface_H_</span></span></div><div class="line"></div><div class="line"><span class="comment">// clang-format on</span></div></pre></td></tr></table></figure>
</li>
</ul>
<p>可以看到其中的具体图已经转换为对应运行时指令。</p>
<p>  其中的BufferInfo标记的是为.o文件中的具体运行时二进制字块</p>
<h1 id="Step-5-编写代码调用AOT模型"><a href="#Step-5-编写代码调用AOT模型" class="headerlink" title="Step 5: 编写代码调用AOT模型"></a>Step 5: 编写代码调用AOT模型</h1><blockquote>
<p>这一步中需要注意最终形成的.so在什么平台进行使用，当我们在移动端（Android）使用时，与C++进行通讯需要JNI的支持所以在这一步需要重新configure Tensorflow源码配置SDK、NDK支持，具体SDK\NDK对应target自行选择</p>
<p>下文中的调用C++代码将采用复合JNI规范的代码编写</p>
</blockquote>
<h2 id="项目Java书写对应native方法生成对应JNI头文件："><a href="#项目Java书写对应native方法生成对应JNI头文件：" class="headerlink" title="项目Java书写对应native方法生成对应JNI头文件："></a>项目Java书写对应native方法生成对应JNI头文件：</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.qihoo.cleandroid.sdk.imageclassfier.core.classfier.process;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"> * Created by zhanghongxin on 2019/7/22.</div><div class="line"> */</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomClassifier</span> </span>&#123;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String LIBNAME = <span class="string">"custom_interface"</span>;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">private</span> <span class="title">CustomClassifier</span><span class="params">()</span> </span>&#123;&#125;</div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line">     * Load the TensorFlowLite runtime C library.</div><div class="line">     */</div><div class="line">    <span class="function"><span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">init</span><span class="params">()</span> </span>&#123;</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            System.loadLibrary(LIBNAME);</div><div class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</div><div class="line">        &#125; <span class="keyword">catch</span> (UnsatisfiedLinkError e) &#123;</div><div class="line">            System.err.println(<span class="string">"custom_interface: failed to load native library: "</span> + e.getMessage());</div><div class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">static</span> &#123;</div><div class="line">        init();</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">native</span> <span class="keyword">void</span> <span class="title">getPredictResult</span><span class="params">(<span class="keyword">float</span>[][][][] input, <span class="keyword">float</span>[][] output, <span class="keyword">int</span> inputSize, <span class="keyword">int</span> outputSize)</span></span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="生成头文件com-qihoo-cleandroid-sdk-imageclassfier-core-classfier-process-CustomClassifier-h"><a href="#生成头文件com-qihoo-cleandroid-sdk-imageclassfier-core-classfier-process-CustomClassifier-h" class="headerlink" title="生成头文件com_qihoo_cleandroid_sdk_imageclassfier_core_classfier_process_CustomClassifier.h"></a>生成头文件<code>com_qihoo_cleandroid_sdk_imageclassfier_core_classfier_process_CustomClassifier.h</code></h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/* DO NOT EDIT THIS FILE - it is machine generated */</span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;jni.h&gt;</span></span></div><div class="line"><span class="comment">/* Header for class com_qihoo_cleandroid_sdk_imageclassfier_core_classfier_process_CustomClassifier */</span></div><div class="line"></div><div class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> _Included_com_qihoo_cleandroid_sdk_imageclassfier_core_classfier_process_CustomClassifier</span></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> _Included_com_qihoo_cleandroid_sdk_imageclassfier_core_classfier_process_CustomClassifier</span></div><div class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> __cplusplus</span></div><div class="line"><span class="keyword">extern</span> <span class="string">"C"</span> &#123;</div><div class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></div><div class="line"><span class="comment">/*</span></div><div class="line"> * Class:     com_qihoo_cleandroid_sdk_imageclassfier_core_classfier_process_CustomClassifier</div><div class="line"> * Method:    getPredictResult</div><div class="line"> * Signature: ([[[[F[[FII)V</div><div class="line"> */</div><div class="line"><span class="function">JNIEXPORT <span class="keyword">void</span> JNICALL <span class="title">Java_com_qihoo_cleandroid_sdk_imageclassfier_core_classfier_process_CustomClassifier_getPredictResult</span></span></div><div class="line">  <span class="params">(JNIEnv *, jclass, jobjectArray, jobjectArray, jint, jint)</span>;</div><div class="line"></div><div class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> __cplusplus</span></div><div class="line">&#125;</div><div class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></div></pre></td></tr></table></figure>
<h2 id="编写C-代码实现模型调用com-qihoo-cleandroid-sdk-imageclassfier-core-classfier-process-CustomClassifier-cc"><a href="#编写C-代码实现模型调用com-qihoo-cleandroid-sdk-imageclassfier-core-classfier-process-CustomClassifier-cc" class="headerlink" title="编写C++代码实现模型调用com_qihoo_cleandroid_sdk_imageclassfier_core_classfier_process_CustomClassifier.cc"></a>编写C++代码实现模型调用<code>com_qihoo_cleandroid_sdk_imageclassfier_core_classfier_process_CustomClassifier.cc</code></h2><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div></pre></td><td class="code"><pre><div class="line">#define EIGEN_USE_THREADS</div><div class="line">#define EIGEN_USE_CUSTOM_THREAD_POOL</div><div class="line"></div><div class="line">#include &lt;iostream&gt;</div><div class="line">#include &lt;cstdio&gt;</div><div class="line">#include &lt;jni.h&gt;</div><div class="line">#include &lt;android/log.h&gt;</div><div class="line">#include "custom_interface_lib.h"</div><div class="line">#include "third_party/eigen3/unsupported/Eigen/CXX11/Tensor"</div><div class="line"></div><div class="line">float* run(float* input, float* output, int input_size, int output_size)&#123;</div><div class="line">        std::cout &lt;&lt; "Load .so SUCCESS" &lt;&lt; std::endl;</div><div class="line">        Eigen::ThreadPool tp(std::thread::hardware_concurrency());</div><div class="line">        Eigen::ThreadPoolDevice device(&amp;tp, tp.NumThreads());</div><div class="line">        Classifier classifier;</div><div class="line">        classifier.set_thread_pool(&amp;device);</div><div class="line"></div><div class="line">        std::copy(input, input + input_size, classifier.arg0_data());</div><div class="line">        auto ok = classifier.Run();</div><div class="line">        if (not ok) std::cout &lt;&lt; "NOT OK" &lt;&lt; std::endl;</div><div class="line">//</div><div class="line">//        std::cout &lt;&lt; "input:";</div><div class="line">//        std::cout &lt;&lt; input &lt;&lt; std::endl;</div><div class="line">//</div><div class="line">//        std::cout &lt;&lt; "input_size:";</div><div class="line">//        std::cout &lt;&lt; input_size &lt;&lt; std::endl;</div><div class="line">//</div><div class="line">//        std::cout &lt;&lt; "classifier.arg0_data():";</div><div class="line">//        std::cout &lt;&lt; classifier.arg0_data() &lt;&lt; std::endl;</div><div class="line">//</div><div class="line">//        std::cout &lt;&lt; "output:";</div><div class="line">//        std::cout &lt;&lt; output &lt;&lt; std::endl;</div><div class="line">//</div><div class="line">//        std::cout &lt;&lt; "output_size:";</div><div class="line">//        std::cout &lt;&lt; output_size &lt;&lt; std::endl;</div><div class="line">//</div><div class="line">//        std::cout &lt;&lt; "result0_data():";</div><div class="line">//        std::cout &lt;&lt; classifier.result0_data() &lt;&lt; std::endl;</div><div class="line">//</div><div class="line">//        for(int i = 0; i &lt; 30; i++)&#123;</div><div class="line">//            std::cout &lt;&lt; "restul0_";</div><div class="line">//            std::cout &lt;&lt; i;</div><div class="line">//            std::cout &lt;&lt; " : ";</div><div class="line">//            std::cout &lt;&lt; classifier.result0(0,i) &lt;&lt; std::endl;</div><div class="line">//            __android_log_print(ANDROID_LOG_INFO, "NATIVE", "~~~~~~~~~OUTPUT== %f~~~~~~~~~~~~~~~\n", classifier.result0(0,i));</div><div class="line">//        &#125;</div><div class="line"></div><div class="line">        std::copy(classifier.result0_data(), classifier.result0_data() + output_size, output);</div><div class="line"></div><div class="line">        return output;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">#ifndef _Included_com_qihoo_cleandroid_sdk_imageclassfier_core_classfier_process_CustomClassifier</div><div class="line">#define _Included_com_qihoo_cleandroid_sdk_imageclassfier_core_classfier_process_CustomClassifier</div><div class="line">#ifdef __cplusplus</div><div class="line">extern "C" &#123;</div><div class="line">#endif</div><div class="line">    JNIEXPORT void JNICALL Java_com_qihoo_cleandroid_sdk_imageclassfier_core_classfier_process_CustomClassifier_getPredictResult</div><div class="line">      (JNIEnv *env, jobject obj, jobjectArray inputArray, jobjectArray outputArray, jint inputSize, jint outputSize)&#123;</div><div class="line">        jboolean isCopy = JNI_FALSE;</div><div class="line"></div><div class="line">          jint rows = env-&gt;GetArrayLength(inputArray);</div><div class="line">//          __android_log_print(ANDROID_LOG_INFO, "NATIVE", "~~~~~~~~~inputRows== %d~~~~~~~~~~~~~~~\n", rows);</div><div class="line">          jobjectArray tempInputArray = (jobjectArray)env-&gt;GetObjectArrayElement(inputArray, 0);</div><div class="line">//          __android_log_print(ANDROID_LOG_INFO, "NATIVE", "~~~~~~~~~input: 1~~~~~~~~~~~~~~\n");</div><div class="line">          jobjectArray tTempInputArray = (jobjectArray)env-&gt;GetObjectArrayElement(tempInputArray, 0);</div><div class="line">//          __android_log_print(ANDROID_LOG_INFO, "NATIVE", "~~~~~~~~~input: 2~~~~~~~~~~~~~~~\n");</div><div class="line">          jobjectArray tTTempInputArray = (jobjectArray)env-&gt;GetObjectArrayElement(tTempInputArray, 0);</div><div class="line">//          __android_log_print(ANDROID_LOG_INFO, "NATIVE", "~~~~~~~~~input: 3~~~~~~~~~~~~~~~\n");</div><div class="line">          jfloat* input = env-&gt;GetFloatArrayElements((jfloatArray)tTTempInputArray, 0);</div><div class="line">//          __android_log_print(ANDROID_LOG_INFO, "NATIVE", "~~~~~~~~~input: %f~~~~~~~~~~~~~~~\n", input);</div><div class="line"></div><div class="line"></div><div class="line">        jobjectArray tempOutputArray = (jobjectArray)env-&gt;GetObjectArrayElement(outputArray,0);</div><div class="line">//        __android_log_print(ANDROID_LOG_INFO, "NATIVE", "~~~~~~~~~output: 1~~~~~~~~~~~~~~~\n");</div><div class="line">        jfloat* output = env-&gt;GetFloatArrayElements((jfloatArray)tempOutputArray, 0);</div><div class="line">//        __android_log_print(ANDROID_LOG_INFO, "NATIVE", "~~~~~~~~~output: %f~~~~~~~~~~~~~~~\n", output);</div><div class="line"></div><div class="line">        jfloat* resultPointer = run(input, output, inputSize, outputSize);</div><div class="line"></div><div class="line">//        jclass floatArrayClz = env-&gt;FindClass("[[F");</div><div class="line">//        if(floatArrayClz == NULL) return NULL;</div><div class="line">//        outputArray = env-&gt;NewObjectArray(outputSize, floatArrayClz, NULL );</div><div class="line">//        if(outputArray == NULL) return NULL;</div><div class="line">        for(int i = 0; i &lt; 1; i++)&#123;</div><div class="line">            jfloat temp[outputSize];</div><div class="line">            jfloatArray floatArray = env-&gt;NewFloatArray(outputSize);</div><div class="line">//            if(floatArray == NULL) return NULL;</div><div class="line">            for(int j=0; j &lt; outputSize; j++)&#123;</div><div class="line">                temp[j] = *(resultPointer + j);</div><div class="line">            &#125;</div><div class="line">//            __android_log_print(ANDROID_LOG_INFO, "NATIVE", "~~~~~~~~~output: 2~~~~~~~~~~~~~~~\n");</div><div class="line">            env-&gt;SetFloatArrayRegion(floatArray, 0, outputSize, temp);</div><div class="line">//            __android_log_print(ANDROID_LOG_INFO, "NATIVE", "~~~~~~~~~output: 3~~~~~~~~~~~~~~~\n");</div><div class="line">            env-&gt;SetObjectArrayElement(outputArray, i, floatArray);</div><div class="line">//            __android_log_print(ANDROID_LOG_INFO, "NATIVE", "~~~~~~~~~output: 4~~~~~~~~~~~~~~~\n");</div><div class="line">            env-&gt;DeleteLocalRef(floatArray);</div><div class="line">        &#125;</div><div class="line">//        __android_log_print(ANDROID_LOG_INFO, "NATIVE", "~~~~~~~~~output: %f~~~~~~~~~~~~~~~\n", outputArray[0]);</div><div class="line">      &#125;</div><div class="line">#ifdef __cplusplus</div><div class="line">&#125;</div><div class="line">#endif</div><div class="line">#endif</div></pre></td></tr></table></figure>
<p><em>此步骤结束</em></p>
<h1 id="Step-6-编写BUILD"><a href="#Step-6-编写BUILD" class="headerlink" title="Step 6: 编写BUILD"></a>Step 6: 编写BUILD</h1><blockquote>
<p>此步骤中所编写的BUILD文件与Step 3中所编写文件为同一文件</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line">cc_library(</div><div class="line">    name = <span class="string">"library"</span>,</div><div class="line">    hdrs = [<span class="string">"custom_interface_lib.h"</span>],</div><div class="line">    srcs = [<span class="string">"custom_interface_tfcompile_function.o"</span>,<span class="string">"custom_interface_tfcompile_metadata.o"</span>],</div><div class="line">)</div><div class="line"></div><div class="line">cc_binary(</div><div class="line">    name = <span class="string">"libcustom_interface.so"</span>,</div><div class="line"></div><div class="line">    srcs = [</div><div class="line">    <span class="string">"com_qihoo_cleandroid_sdk_imageclassfier_core_classfier_process_CustomClassifier.h"</span>,</div><div class="line">    <span class="string">"com_qihoo_cleandroid_sdk_imageclassfier_core_classfier_process_CustomClassifier.cc"</span>,</div><div class="line">    ],</div><div class="line"></div><div class="line">    deps = [</div><div class="line">    <span class="string">":library"</span>,</div><div class="line">    <span class="string">"//tensorflow/compiler/tf2xla:xla_compiled_cpu_function"</span>,</div><div class="line">    <span class="string">"//tensorflow/core:framework_lite"</span>,</div><div class="line">    <span class="string">"//tensorflow/compiler/xla:cpu_function_runtime"</span>,</div><div class="line">    <span class="string">"//tensorflow/compiler/xla/service/cpu:runtime_conv2d"</span>,</div><div class="line">    <span class="string">"//tensorflow/compiler/xla/service/cpu:runtime_matmul"</span>,</div><div class="line">    <span class="string">"//third_party/eigen3"</span>,</div><div class="line">    ],</div><div class="line"></div><div class="line">    linkopts = [</div><div class="line">    <span class="string">"-landroid"</span>,</div><div class="line">    <span class="string">"-shared"</span>,</div><div class="line">    ],</div><div class="line"></div><div class="line">    linkshared = 1,</div><div class="line"></div><div class="line">    linkstatic = 1,</div><div class="line"></div><div class="line">    copts = [<span class="string">"-fPIC"</span>],</div><div class="line">)</div></pre></td></tr></table></figure>
<p>其中cc_binary中的name即为生成.so的名称该名称应符合JNI规范</p>
<p>注意生成.so动态链接库时需配置<code>linkshared = 1</code> <code>linkstatic = 1</code> </p>
<h1 id="Step-7-编译对应平台最终产物-so"><a href="#Step-7-编译对应平台最终产物-so" class="headerlink" title="Step 7: 编译对应平台最终产物 .so"></a>Step 7: 编译对应平台最终产物 .so</h1><p>运行命令：<code>bazel build -c opt //tensorflow/compiler/aot/custom:libcustom_interface.so \ --crosstool_top=//external:android/crosstool \ --host_crosstool_top=@bazel_tools//tools/cpp:toolchain \ --cpu=armeabi-v7a</code></p>
<p>通过<code>--cpu=xxx</code>来控制编译对应平台ABI的.so</p>
<p><em>至此编译后所有步骤完成</em></p>
<h1 id="实验结论"><a href="#实验结论" class="headerlink" title="实验结论"></a>实验结论</h1><p>通过XLA加速接入移动端对比（其实并没有可比性因为没有控制变量）</p>
<figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.loli.net/2019/07/30/5d3fd9484d72823389.png" alt="对比" title="">
                </div>
                <div class="image-caption">对比</div>
            </figure>
<p>上图中显示了在lite和xla两种方式下使用同一种机型预测174张图片的耗时对比数据</p>
<p>明显lite在这一方面速度非常有优势，但并不代表XLA不起作用，而是恰巧在我们的计算图中使用的卷积网络在这种情况下不适用于XLA进行优化，官方使用JIT的速度对比，其实在JIT的训练时数据和AOT的运行时数据事实上是对应关系恰巧反应了这一关系。</p>
<p>后附几张官方演示图：</p>
<ul>
<li><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.loli.net/2019/07/30/5d3fdb4d90ce710040.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
</li>
<li><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.loli.net/2019/07/30/5d3fd82750fad80574.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
</li>
<li><figure class="image-bubble">
                <div class="img-lightbox">
                    <div class="overlay"></div>
                    <img src="https://i.loli.net/2019/07/30/5d3fd82760ed015529.png" alt="" title="">
                </div>
                <div class="image-caption"></div>
            </figure>
</li>
</ul>
<hr>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li><p><a href="https://carlthome.github.io/posts/tfcompile /" target="_blank" rel="external">tfcompile | Carl Thomé</a></p>
</li>
<li><p><a href="https://www.tensorflow.org/xla/tfcompile" target="_blank" rel="external">Using AOT compilation  |  XLA  |  TensorFlow</a></p>
</li>
<li><p><a href="https://github.com/rongjiecomputer/tensorflow-xla-aot-windows" target="_blank" rel="external">GitHub - rongjiecomputer/tensorflow-xla-aot-windows: Guide to build and use Tensorflow XLA/AOT on Windows</a></p>
</li>
<li><p><a href="https://stackoverflow.com/questions/43673380/tensorflow-cross-compile-xla-to-android" target="_blank" rel="external">c++ - TensorFlow: cross-compile XLA to Android - Stack Overflow</a></p>
</li>
<li><p><a href="https://danny270degree.blogspot.com/" target="_blank" rel="external">danny270degree.blogspot.com</a></p>
</li>
<li><p><a href="https://qiita.com/qiita_kuru/items/71660124b807c00ace31" target="_blank" rel="external">Tensorflow AOT (tfcompile)の使い方 - Qiita</a></p>
</li>
<li><p><a href="https://danny270degree.blogspot.com/2018/06/xla-how-to-use-xla-aot-compilation-in.html" target="_blank" rel="external">Danny’s tech notebook | 丹尼技術手札: [XLA 研究] How to use XLA AOT compilation in TensorFlow</a></p>
</li>
<li><p><a href="http://www.bnee.net/article/73899.html" target="_blank" rel="external">学习笔记TF062:TensorFlow线性代数编译框架XLA / bnee.net</a></p>
</li>
<li><p><a href="https://www.wandouip.com/t5i207350/" target="_blank" rel="external">TF加速-AOT之tfcompile趟坑 - 豌豆ip代理</a></p>
</li>
<li><p><a href="https://github.com/bazelbuild/bazel/issues/5164" target="_blank" rel="external">Issue #5164 · bazelbuild/bazel · GitHub</a></p>
</li>
<li><p><a href="https://barkeywolf.consulting/posts/tf-aot-rust/" target="_blank" rel="external">Barkey Wolf Consulting - Ahead-of-time compilation of a Tensorflow model for lightweight inclusion in a Rust program</a></p>
</li>
<li><p><a href="https://github.com/tensorflow/tensorflow/issues/7288" target="_blank" rel="external">Are linkopts propagated from copts and/or deps ? · Issue #7288 · tensorflow/tensorflow</a></p>
</li>
<li><p><a href="https://blog.csdn.net/zhuiqiuk/article/details/54428818" target="_blank" rel="external">Build TensorFlow for armeabi-v7a and arm64-v8a - zhuiqiuk的专栏 - CSDN博客</a></p>
</li>
</ul>

        </div>

        <blockquote class="post-copyright">
    
    <div class="content">
        
<span class="post-time">
    Last updated: <time datetime="2019-07-31T06:14:25.995Z" itemprop="dateUpdated">2019-07-31 14:14:25</time>
</span><br>


        
        Original Link：<a href="/2019/07/29/Tensorflow XLA AOT 模型优化/" target="_blank" rel="external">https://edward7zhang.github.io/2019/07/29/Tensorflow XLA AOT 模型优化/</a>
        
    </div>
    
    <footer>
        <a href="https://edward7zhang.github.io">
            <img src="/img/avatar.jpg" alt="EdwardZhang">
            EdwardZhang
        </a>
    </footer>
</blockquote>

        


        <div class="post-footer">
            
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DeepLearning/">DeepLearning</a></li></ul>


            
<div class="page-share-wrap">
    

<div class="page-share" id="pageShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=https://edward7zhang.github.io/2019/07/29/Tensorflow XLA AOT 模型优化/&title=《Tensroflow XLA AOT 模型优化》 — EdwardZhang's Blog&pic=https://edward7zhang.github.io/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=https://edward7zhang.github.io/2019/07/29/Tensorflow XLA AOT 模型优化/&title=《Tensroflow XLA AOT 模型优化》 — EdwardZhang's Blog&source=Life starts at the end of your comfort zone." data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https://edward7zhang.github.io/2019/07/29/Tensorflow XLA AOT 模型优化/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《Tensroflow XLA AOT 模型优化》 — EdwardZhang's Blog&url=https://edward7zhang.github.io/2019/07/29/Tensorflow XLA AOT 模型优化/&via=https://edward7zhang.github.io" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=https://edward7zhang.github.io/2019/07/29/Tensorflow XLA AOT 模型优化/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>



    <a href="javascript:;" id="shareFab" class="page-share-fab waves-effect waves-circle">
        <i class="icon icon-share-alt icon-lg"></i>
    </a>
</div>



        </div>
    </div>

    
<nav class="post-nav flex-row flex-justify-between flex-row-reverse">
  

  
    <div class="waves-block waves-effect next">
      <a href="/2019/06/01/想说却还没说的也不必再说了/" id="post-next" class="post-nav-link">
        <div class="tips">Next <i class="icon icon-angle-right icon-lg icon-pl"></i></div>
        <h4 class="title">想说却还没说的也不必再说了</h4>
      </a>
    </div>
  
</nav>



    


<section class="comments" id="comments">
    <div id="disqus_thread"></div>
    <script>
    var disqus_shortname = 'EdwardZhang777';
    lazyScripts.push('//' + disqus_shortname + '.disqus.com/embed.js')
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>













</article>



</div>

        <footer class="footer">
    <div class="top">
        
<p>
    <span id="busuanzi_container_site_uv" style='display:none'>
        站点总访客数：<span id="busuanzi_value_site_uv"></span>
    </span>
    <span id="busuanzi_container_site_pv" style='display:none'>
        站点总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
</p>


        <p>
            
                <span><a href="/atom.xml" target="_blank" class="rss" title="rss"><i class="icon icon-lg icon-rss"></i></a></span>
            
            <span>This blog is licensed under a <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.</span>
        </p>
    </div>
    <div class="bottom">
        <p><span>EdwardZhang &copy; 2016 - 2019</span>
            <span>
                
                Power by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme <a href="https://github.com/yscoder/hexo-theme-indigo" target="_blank">indigo</a>
            </span>
        </p>
    </div>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>



<div class="global-share" id="globalShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=https://edward7zhang.github.io/2019/07/29/Tensorflow XLA AOT 模型优化/&title=《Tensroflow XLA AOT 模型优化》 — EdwardZhang's Blog&pic=https://edward7zhang.github.io/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=https://edward7zhang.github.io/2019/07/29/Tensorflow XLA AOT 模型优化/&title=《Tensroflow XLA AOT 模型优化》 — EdwardZhang's Blog&source=Life starts at the end of your comfort zone." data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https://edward7zhang.github.io/2019/07/29/Tensorflow XLA AOT 模型优化/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《Tensroflow XLA AOT 模型优化》 — EdwardZhang's Blog&url=https://edward7zhang.github.io/2019/07/29/Tensorflow XLA AOT 模型优化/&via=https://edward7zhang.github.io" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=https://edward7zhang.github.io/2019/07/29/Tensorflow XLA AOT 模型优化/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>


<div class="page-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAN4AAADeCAAAAAB3DOFrAAACpklEQVR42u3aQVLDMAwF0N7/0uUAkPAlWSXMPK8YaBM/L2zx5dcrHu9v4+ozV5+/H1dPuHr+4YGHh4c3nvrVi+9/c//kZNLVT97PGQ8PD2+bl2z0CXVyGORLmcwZDw8P72m86raef+b+mMHDw8P7v7z7b+Wlc1I04+Hh4T2TVy1884AgCYKTQ2I9a8HDw8OLeZNy9q9+Xunv4eHh4Y276nkzbOONB64j4OHh4S3wquVsr4TdaInllxXw8PDwNnj3oUD19fnFqWoYkQfKeHh4eHu8fKPPA9l8yfLNfRTO4uHh4a3x8oZ9dROfFN/V5fjhfwU8PDy8ZV5vQ59M61RhXU4m8PDw8Fq8XhhR/VY1vOi14qJDCA8PD2+N13tQkhlXwdUWXbPGx8PDw4t5SWFavRQ1WaxJoY+Hh4f3GV41bD0VyCYL1PsWHh4e3jYv37j3wMnVhOqxdHnpCg8PD+8Qb9Lmn0QVp5Y1yqTx8PDwFni9K1a9gjgPO3pPwMPDw9vm5Q34pKg9VWTPr3/h4eHhbfDywDRn5MFBtTHWzGbx8PDwlnnJyHtrSWHdCzIKd8rw8PDwjvKSi03HooGg/K0eEs0jAQ8PD2+NV22DVRm9A6Z86QoPDw/vKC+PG3qTmwcW84XDw8PD2+OdvQqQRBLVttboYMDDw8P7CK8aWFRji8LmHi9W4WDAw8PDO8TLS9jq5p4X072wIyqp8fDw8Ma8d3FUo4Rq6NB77y9XB/Dw8PCO8vIx2conB0A1KMHDw8P7DC8/DJIKPQ8X8sC3ejBc9vfw8PDwjvJ6naNe+dtreuVPwMPDw3smrzrRqFk1CIsvlxIPDw/vAbzetE5dS82PHDw8PLxt3rzp1QsR1st3PDw8vN1kYHR4RAVu8NfqMXNg4OHh4aW8L6gR7gOv/fi9AAAAAElFTkSuQmCC" alt="微信分享二维码">
</div>




    <script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: true, REWARD: false };


</script>

<script src="//unpkg.com/hexo-theme-material-indigo@latest/js/main.min.js"></script>


<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<template id="search-tpl">
<li class="item">
    <a href="{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</template>

<script src="//unpkg.com/hexo-theme-material-indigo@latest/js/search.min.js" async></script>



<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" async></script>




<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>



<script>
(function() {
    var OriginTitile = document.title, titleTime;
    document.addEventListener('visibilitychange', function() {
        if (document.hidden) {
            document.title = '42';
            clearTimeout(titleTime);
        } else {
            document.title = 'Don‘t Panic！';
            titleTime = setTimeout(function() {
                document.title = OriginTitile;
            },2000);
        }
    });
})();
</script>



</body>
</html>
